{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-708d46d3f9180abe",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Multi-Modal Data Fusion - Project Work: Multi-Modal Physical Exercise Classification\n",
    "\n",
    "\n",
    "In this project, real multi-modal data is studied by utilizing different techniques presented during the course. In addition, there is an optional task to try some different approaches to identify persons from the same dataset. Open MEx dataset from UCI machine learning repository is used. Idea is to apply different techniques to recognize physical exercises from wearable sensors and depth camera, user-independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author(s)\n",
    "Add your information here\n",
    "\n",
    "Name(s): Nipun Waas\n",
    "\n",
    "Student number(s): 2305414"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32738734cf6f1a4f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Description \n",
    "\n",
    "The goal of this project is to develop user-independent pre-processing and classification models to recognize 7 different physical exercises measured by accelerometer (attached to subject's thigh) and depth camera (above the subject facing downwards recording an aerial view). All the exercises were performed subject lying down on the mat. Original dataset have also another acceleration sensor and pressure-sensitive mat, but those two modalities are ommited in this project. There are totally 30 subjects in the original dataset, and in this work subset of 10 person is utilized. Detailed description of the dataset and original data can be access in [MEx dataset @ UCI machine learning repository](https://archive.ics.uci.edu/ml/datasets/MEx#). We are providing the subset of dataset in Moodle.\n",
    "\n",
    "The project work is divided on following phases:\n",
    "\n",
    "1. Data preparation, exploration, and visualization\n",
    "2. Feature extraction and unimodal fusion for classification\n",
    "3. Feature extraction and feature-level fusion for multimodal classification\n",
    "4. Decision-level fusion for multimodal classification\n",
    "5. Bonus task: Multimodal biometric identification of persons\n",
    "\n",
    "where 1-4 are compulsory (max. 10 points each), and 5 is optional to get bonus points (max. 5+5 points). In each phase, you should visualize and analyse the results and document the work and findings properly by text blocks and figures between the code. <b> Nice looking </b> and <b> informative </b> notebook representing your results and analysis will be part of the grading in addition to actual implementation.\n",
    "\n",
    "The results are validated using confusion matrices and F1 scores. F1 macro score is given as \n",
    "<br>\n",
    "<br>\n",
    "$\n",
    "\\begin{equation}\n",
    "F1_{macro} = \\frac{1}{N} \\sum_i^N F1_i,\n",
    "\\end{equation}\n",
    "$\n",
    "<br>\n",
    "<br>\n",
    "where $F1_i = 2  \\frac{precision_i * recall_i}{precision_i + recall_i}$, and $N$ is the number of classes.\n",
    "<br>\n",
    "\n",
    "## Learning goals \n",
    "\n",
    "After the project work, you should  \n",
    "\n",
    "- be able to study real world multi-modal data\n",
    "- be able to apply different data fusion techniques to real-world problem\n",
    "- be able to evaluate the results\n",
    "- be able to analyse the outcome\n",
    "- be able to document your work properly\n",
    "\n",
    "## Relevant lectures\n",
    "\n",
    "Lectures 1-8\n",
    "\n",
    "## Relevant exercises\n",
    "\n",
    "Exercises 0-6\n",
    "\n",
    "## Relevant chapters in course book\n",
    "\n",
    "Chapter 1-14\n",
    "\n",
    "## Additional Material \n",
    "\n",
    "* Original dataset [MEx dataset @ UCI machine learning repository](https://archive.ics.uci.edu/ml/datasets/MEx#)\n",
    "* Related scientific article [MEx: Multi-modal Exercises Dataset for Human Activity Recognition](https://arxiv.org/pdf/1908.08992.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e096db2d9e8c24e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# 1. Data preparation, exploration, and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bacbb8f5ae7a2e4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='task1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Assigment.</b> <b>Task 1.</b>\n",
    "\n",
    "Download data from the Moodle's Project section. Get yourself familiar with the folder structure and data. You can read the data files using the function given below. Each file consists one exercise type performed by single user. Data are divided on multiple folders. Note that, in each folder there is one long sequence of single exercise, except exercise 4 which is performed two times in different ways. Those two sequences belongs to same class. Do the following subtasks to pre-analyse data examples and to prepare the training and testing data for next tasks:\n",
    "<br>\n",
    "<br> \n",
    "<p> Read raw data from the files. Prepare and divide each data file to shorter sequences using windowing method. Similar to related article \"MEx: Multi-modal Exercises Dataset for Human Activity Recognition\", use 5 second window and 3 second overlapping between windows, producing several example sequences from one exercise file for classification purposes. Windowing is working so that starting from the beginning of each long exercise sequence, take 5 seconds of data points (from synchronized acceleration data and depth images) based on the time stamps. Next, move the window 2 seconds forward and take another 5 seconds of data. Then continue this until your are at the end of sequence. Each window will consists 500x3 matrix of acceleration data and 5x192 matrix of depth image data.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries here\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Enter data folder location\n",
    "loc = \"./MEx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5b805f4284f1480c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records found: 160\n",
      "Dataframe with all records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>exercise_id</th>\n",
       "      <th>trial</th>\n",
       "      <th>sensor_code</th>\n",
       "      <th>sensor</th>\n",
       "      <th>df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>act</td>\n",
       "      <td>acc</td>\n",
       "      <td>time     acc_0     acc_1     acc_2\n",
       "0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03</td>\n",
       "      <td>04</td>\n",
       "      <td>2</td>\n",
       "      <td>act</td>\n",
       "      <td>acc</td>\n",
       "      <td>time     acc_0     acc_1     acc_2\n",
       "0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03</td>\n",
       "      <td>06</td>\n",
       "      <td>1</td>\n",
       "      <td>act</td>\n",
       "      <td>acc</td>\n",
       "      <td>time     acc_0     acc_1     acc_2\n",
       "0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>act</td>\n",
       "      <td>acc</td>\n",
       "      <td>time     acc_0     acc_1     acc_2\n",
       "0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03</td>\n",
       "      <td>03</td>\n",
       "      <td>1</td>\n",
       "      <td>act</td>\n",
       "      <td>acc</td>\n",
       "      <td>time     acc_0     acc_1     acc_2\n",
       "0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id exercise_id  trial sensor_code sensor  \\\n",
       "0         03          02      1         act    acc   \n",
       "1         03          04      2         act    acc   \n",
       "2         03          06      1         act    acc   \n",
       "3         03          04      1         act    acc   \n",
       "4         03          03      1         act    acc   \n",
       "\n",
       "                                                  df  \n",
       "0           time     acc_0     acc_1     acc_2\n",
       "0 ...  \n",
       "1           time     acc_0     acc_1     acc_2\n",
       "0 ...  \n",
       "2           time     acc_0     acc_1     acc_2\n",
       "0 ...  \n",
       "3           time     acc_0     acc_1     acc_2\n",
       "0 ...  \n",
       "4           time     acc_0     acc_1     acc_2\n",
       "0 ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe with one measurement series:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>acc_0</th>\n",
       "      <th>acc_1</th>\n",
       "      <th>acc_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>-0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>0.493750</td>\n",
       "      <td>-0.365625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>-0.368750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>0.494792</td>\n",
       "      <td>-0.364583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>0.489063</td>\n",
       "      <td>-0.370312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time     acc_0     acc_1     acc_2\n",
       "0   0.0 -0.765625  0.484375 -0.375000\n",
       "1  10.0 -0.765625  0.493750 -0.365625\n",
       "2  20.0 -0.765625  0.490625 -0.368750\n",
       "3  30.0 -0.765625  0.494792 -0.364583\n",
       "4  40.0 -0.765625  0.489063 -0.370312"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    IMPORTANT: PLEASE DO NOT MODIFY THE CODE IN THIS CELL.\n",
    "\"\"\"\n",
    "def path_to_meta(p):\n",
    "    meta = dict()\n",
    "    meta[\"subject_id\"] = p.parent.stem\n",
    "    meta[\"exercise_id\"] = p.stem.split(\"_\")[-2]\n",
    "    meta[\"trial\"] = int(p.stem.split(\"_\")[-1])\n",
    "    meta[\"sensor_code\"] = p.stem.split(\"_\")[0]\n",
    "    meta[\"sensor\"] = {\"act\": \"acc\", \"dc\": \"dc\"}[meta[\"sensor_code\"]]\n",
    "    return meta\n",
    "\n",
    "# Find, read, and compose the measurements\n",
    "paths_record = Path(loc).glob(\"*/*/*.csv\")\n",
    "\n",
    "records = []\n",
    "\n",
    "for path_record in paths_record:\n",
    "    df = pd.read_csv(path_record, delimiter=\",\", header=None)\n",
    "    meta = path_to_meta(path_record)\n",
    "    \n",
    "    if meta[\"sensor\"] == \"acc\":\n",
    "        col_names = [\"time\", \"acc_0\", \"acc_1\", \"acc_2\"]\n",
    "        df.columns = col_names\n",
    "    else:\n",
    "        num_cols = df.shape[1]\n",
    "        col_names = [\"time\", ] + [f\"dc_{i}\" for i in range(num_cols-1)]\n",
    "        df.columns = col_names\n",
    "\n",
    "    meta[\"df\"] = df\n",
    "    \n",
    "    records.append(meta)\n",
    "\n",
    "df_records = pd.DataFrame.from_records(records)\n",
    "\n",
    "print(f\"Total records found: {len(df_records)}\")\n",
    "print(\"Dataframe with all records:\")\n",
    "display(df_records.head())\n",
    "print(\"Dataframe with one measurement series:\")\n",
    "display(df_records[\"df\"].iloc[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8aebacdeb29d491",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows extracted: 4169\n",
      "Dataframe with all windowed records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>exercise_id</th>\n",
       "      <th>trial</th>\n",
       "      <th>sensor_code</th>\n",
       "      <th>sensor</th>\n",
       "      <th>df</th>\n",
       "      <th>window_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>act</td>\n",
       "      <td>acc</td>\n",
       "      <td>time     acc_0     acc_1     acc_2\n",
       "0   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>act</td>\n",
       "      <td>acc</td>\n",
       "      <td>time     acc_0     acc_1     acc_2\n",
       "200 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>act</td>\n",
       "      <td>acc</td>\n",
       "      <td>time     acc_0     acc_1     acc_2\n",
       "400 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>act</td>\n",
       "      <td>acc</td>\n",
       "      <td>time     acc_0     acc_1     acc_2\n",
       "60...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>act</td>\n",
       "      <td>acc</td>\n",
       "      <td>time     acc_0     acc_1     acc_2\n",
       "80...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id exercise_id  trial sensor_code sensor  \\\n",
       "0         03          02      1         act    acc   \n",
       "1         03          02      1         act    acc   \n",
       "2         03          02      1         act    acc   \n",
       "3         03          02      1         act    acc   \n",
       "4         03          02      1         act    acc   \n",
       "\n",
       "                                                  df  window_idx  \n",
       "0         time     acc_0     acc_1     acc_2\n",
       "0   ...           0  \n",
       "1         time     acc_0     acc_1     acc_2\n",
       "200 ...           1  \n",
       "2         time     acc_0     acc_1     acc_2\n",
       "400 ...           2  \n",
       "3           time     acc_0     acc_1     acc_2\n",
       "60...           3  \n",
       "4           time     acc_0     acc_1     acc_2\n",
       "80...           4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe with one windowed measurement series:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>acc_0</th>\n",
       "      <th>acc_1</th>\n",
       "      <th>acc_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>-0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>0.493750</td>\n",
       "      <td>-0.365625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>-0.368750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>0.494792</td>\n",
       "      <td>-0.364583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>0.489063</td>\n",
       "      <td>-0.370312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time     acc_0     acc_1     acc_2\n",
       "0   0.0 -0.765625  0.484375 -0.375000\n",
       "1  10.0 -0.765625  0.493750 -0.365625\n",
       "2  20.0 -0.765625  0.490625 -0.368750\n",
       "3  30.0 -0.765625  0.494792 -0.364583\n",
       "4  40.0 -0.765625  0.489063 -0.370312"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    IMPORTANT: PLEASE DO NOT MODIFY THE CODE IN THIS CELL.\n",
    "\"\"\"\n",
    "\n",
    "# Extract 5-second long windows with 2-second shift (3-second overlap)\n",
    "\n",
    "records_windowed = []\n",
    "\n",
    "time_window = 5000.\n",
    "time_offset = 2000.\n",
    "    \n",
    "for row_idx, row_data in df_records.iterrows():\n",
    "    df_tmp = row_data[\"df\"]\n",
    "    time_start = np.min(df_tmp[\"time\"].to_numpy())\n",
    "    time_end = np.max(df_tmp[\"time\"].to_numpy())\n",
    "    \n",
    "    for window_idx, t0 in enumerate(np.arange(time_start, time_end, time_offset)):\n",
    "        t1 = t0 + time_window\n",
    "        # Handle boundary conditions - skip the measurements from the end shorter than window size\n",
    "        if t1 > time_end:\n",
    "            continue\n",
    "        \n",
    "        tmp_data = deepcopy(row_data)\n",
    "        tmp_data[\"window_idx\"] = window_idx\n",
    "        tmp_data[\"df\"] = df_tmp[(df_tmp[\"time\"] >= t0) &\n",
    "                                (df_tmp[\"time\"] < t1)].copy()\n",
    "        \n",
    "        records_windowed.append(tmp_data)\n",
    "        \n",
    "df_records_windowed = pd.DataFrame.from_records(records_windowed)\n",
    "\n",
    "print(f\"Total windows extracted: {len(df_records_windowed)}\")\n",
    "print(\"Dataframe with all windowed records:\")\n",
    "display(df_records_windowed.head())\n",
    "print(\"Dataframe with one windowed measurement series:\")\n",
    "display(df_records_windowed[\"df\"].iloc[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "     \n",
    "<p> <b>1.1</b> Plot few examples of prepared data for each modalities (accelometer and depth camera). Plot acceleration sensor as multi-dimensional time-series and depth camera data as 2D image. Plot 5 second acceleration sensor and depth image sequences of person 1 and 5 performing exercises 2, 5, and 6. Take the first windowed example from the long exercise sequence. </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1. Visualize selected samples for both modalities\n",
    "\n",
    "### Your code begins here ###\n",
    "\n",
    "\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "<p> <b>1.2</b> Split the prepared dataset to training and testing datasets so that data of persons 1-7 are used for training and data of persons 8-10 are used for testing. In next tasks, training dataset could be further divided on (multiple) validation data folds to tune the models parameters, when needed.<br>\n",
    "    \n",
    "<p> Note: Training set should have 1486 windows and testing set should have 598 windows. In training set, acceleration data will have a window without a pair with depth camera data, that window should be dropped as it doesn't have a pair.<p>\n",
    "  \n",
    "Document your work, calculate the indicator statistics of training and testing datasets (number of examples, dimensions of each example) and visualize prepared examples.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id exercise_id  trial sensor_code sensor  \\\n",
      "0          03          02      1         act    acc   \n",
      "1          03          02      1         act    acc   \n",
      "2          03          02      1         act    acc   \n",
      "3          03          02      1         act    acc   \n",
      "4          03          02      1         act    acc   \n",
      "5          03          02      1         act    acc   \n",
      "6          03          02      1         act    acc   \n",
      "7          03          02      1         act    acc   \n",
      "8          03          02      1         act    acc   \n",
      "9          03          02      1         act    acc   \n",
      "10         03          02      1         act    acc   \n",
      "11         03          02      1         act    acc   \n",
      "12         03          02      1         act    acc   \n",
      "13         03          02      1         act    acc   \n",
      "14         03          02      1         act    acc   \n",
      "15         03          02      1         act    acc   \n",
      "16         03          02      1         act    acc   \n",
      "17         03          02      1         act    acc   \n",
      "18         03          02      1         act    acc   \n",
      "19         03          02      1         act    acc   \n",
      "20         03          02      1         act    acc   \n",
      "21         03          02      1         act    acc   \n",
      "22         03          02      1         act    acc   \n",
      "23         03          02      1         act    acc   \n",
      "24         03          02      1         act    acc   \n",
      "25         03          02      1         act    acc   \n",
      "26         03          02      1         act    acc   \n",
      "27         03          02      1         act    acc   \n",
      "28         03          02      1         act    acc   \n",
      "29         03          02      1         act    acc   \n",
      "30         03          02      1         act    acc   \n",
      "31         03          02      1         act    acc   \n",
      "32         03          02      1         act    acc   \n",
      "33         03          02      1         act    acc   \n",
      "34         03          02      1         act    acc   \n",
      "35         03          02      1         act    acc   \n",
      "36         03          02      1         act    acc   \n",
      "37         03          02      1         act    acc   \n",
      "38         03          04      2         act    acc   \n",
      "39         03          04      2         act    acc   \n",
      "40         03          04      2         act    acc   \n",
      "41         03          04      2         act    acc   \n",
      "42         03          04      2         act    acc   \n",
      "43         03          04      2         act    acc   \n",
      "44         03          04      2         act    acc   \n",
      "45         03          04      2         act    acc   \n",
      "46         03          04      2         act    acc   \n",
      "47         03          04      2         act    acc   \n",
      "48         03          04      2         act    acc   \n",
      "49         03          04      2         act    acc   \n",
      "\n",
      "                                                   df  window_idx  \n",
      "0          time     acc_0     acc_1     acc_2\n",
      "0   ...           0  \n",
      "1          time     acc_0     acc_1     acc_2\n",
      "200 ...           1  \n",
      "2          time     acc_0     acc_1     acc_2\n",
      "400 ...           2  \n",
      "3            time     acc_0     acc_1     acc_2\n",
      "60...           3  \n",
      "4            time     acc_0     acc_1     acc_2\n",
      "80...           4  \n",
      "5            time     acc_0     acc_1     acc_2\n",
      "10...           5  \n",
      "6            time     acc_0     acc_1     acc_2\n",
      "12...           6  \n",
      "7            time     acc_0     acc_1     acc_2\n",
      "14...           7  \n",
      "8            time     acc_0     acc_1     acc_2\n",
      "16...           8  \n",
      "9            time     acc_0     acc_1     acc_2\n",
      "18...           9  \n",
      "10           time     acc_0     acc_1     acc_2\n",
      "20...          10  \n",
      "11           time     acc_0     acc_1     acc_2\n",
      "22...          11  \n",
      "12           time     acc_0     acc_1     acc_2\n",
      "24...          12  \n",
      "13           time     acc_0     acc_1     acc_2\n",
      "26...          13  \n",
      "14           time     acc_0     acc_1     acc_2\n",
      "28...          14  \n",
      "15           time     acc_0     acc_1     acc_2\n",
      "30...          15  \n",
      "16           time     acc_0     acc_1     acc_2\n",
      "32...          16  \n",
      "17           time  acc_0     acc_1     acc_2\n",
      "3400 ...          17  \n",
      "18           time     acc_0     acc_1     acc_2\n",
      "36...          18  \n",
      "19           time     acc_0     acc_1     acc_2\n",
      "38...          19  \n",
      "20           time     acc_0     acc_1     acc_2\n",
      "40...          20  \n",
      "21           time     acc_0     acc_1     acc_2\n",
      "42...          21  \n",
      "22           time     acc_0     acc_1     acc_2\n",
      "44...          22  \n",
      "23           time     acc_0     acc_1     acc_2\n",
      "46...          23  \n",
      "24           time     acc_0     acc_1     acc_2\n",
      "48...          24  \n",
      "25           time  acc_0     acc_1     acc_2\n",
      "5000 ...          25  \n",
      "26           time     acc_0     acc_1     acc_2\n",
      "52...          26  \n",
      "27           time     acc_0     acc_1     acc_2\n",
      "54...          27  \n",
      "28           time     acc_0     acc_1     acc_2\n",
      "56...          28  \n",
      "29           time     acc_0     acc_1     acc_2\n",
      "58...          29  \n",
      "30           time     acc_0     acc_1     acc_2\n",
      "60...          30  \n",
      "31           time     acc_0     acc_1     acc_2\n",
      "62...          31  \n",
      "32           time     acc_0     acc_1     acc_2\n",
      "64...          32  \n",
      "33           time     acc_0     acc_1     acc_2\n",
      "66...          33  \n",
      "34           time     acc_0     acc_1     acc_2\n",
      "68...          34  \n",
      "35           time     acc_0     acc_1     acc_2\n",
      "70...          35  \n",
      "36           time     acc_0     acc_1     acc_2\n",
      "72...          36  \n",
      "37           time     acc_0     acc_1     acc_2\n",
      "74...          37  \n",
      "38         time     acc_0     acc_1     acc_2\n",
      "0   ...           0  \n",
      "39         time     acc_0     acc_1     acc_2\n",
      "200 ...           1  \n",
      "40         time     acc_0     acc_1     acc_2\n",
      "400 ...           2  \n",
      "41           time     acc_0     acc_1     acc_2\n",
      "60...           3  \n",
      "42           time     acc_0     acc_1     acc_2\n",
      "80...           4  \n",
      "43           time     acc_0     acc_1     acc_2\n",
      "10...           5  \n",
      "44           time     acc_0     acc_1     acc_2\n",
      "12...           6  \n",
      "45           time     acc_0     acc_1     acc_2\n",
      "14...           7  \n",
      "46           time     acc_0     acc_1     acc_2\n",
      "16...           8  \n",
      "47           time     acc_0     acc_1     acc_2\n",
      "18...           9  \n",
      "48           time     acc_0     acc_1     acc_2\n",
      "20...          10  \n",
      "49           time     acc_0     acc_1     acc_2\n",
      "22...          11  \n"
     ]
    }
   ],
   "source": [
    "# 1.2. Split samples based on subject ID into training and testing datasets for futher experiments\n",
    "\n",
    "### Your code begins here ###\n",
    "\n",
    "training_set =  df_records_windowed[df_records_windowed[\"subject_id\"].isin(['01', '02', '03', '04', '05', '06', '07'])]\n",
    "testing_set =  df_records_windowed[df_records_windowed[\"subject_id\"].isin(['08', '09', '10'])]\n",
    "\n",
    "print(df_records_windowed.head(50))\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8dd9cccbd7bb483c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2. Feature extraction and fusion for unimodal classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-583b0e4a5d64720f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='task2'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Assigment.</b> <b>Task 2.</b>\n",
    "\n",
    "Use the training dataset prepared in task 1. to build models based on the combination of principal component analysis (PCA), linear discriminant analysis (LDA), and nearest neighbour (NN) classifier for each modality separately and evaluate the model on test dataset. Do the subtasks given as \n",
    "<br>\n",
    "<br>\n",
    "<p> <b>2.1</b> Calculate PCA and LDA transformations to reduce the dimensionality of accelerometer data (e.g., using scikit-learn implementations). Before transformations downsample data from 100 Hz to 25 Hz (using scipy.signal.resample) to get 125x3 matrix of data for each 5 sec window. You should also standardize the values to zero mean and unit variance before the transformations. Using training dataset, fit PCA with 5-dimensional subspace (i.e., choosing the 5 largest principal components) and fit LDA with 5-dimensional subspace. Transform both train and test examples to this low-dimensional feature representation. Concatenate each sequence to single vector size of 3x(5+5). Perform the fusion of PCA and LDA similar manner as presented in Lecture 3 (pages 24-25) using NN method. Evaluate the performance on testset. Show confusion matrix and F1 scores of the results. </p>\n",
    "\n",
    "Note: Standardize the data along each axis.\n",
    "<br>\n",
    "\n",
    "Document your work, evaluate the results, and analyse the outcomes (The expected F1 score for this task should generally fall within the range of 40 to 50)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1\n",
    "\n",
    "### Your code begins here ###\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task2'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "<p> <b>2.2</b> Use PCA and LDA transformations to reduce the dimensionality of depth images. You should also standardize the values to zero mean and unit variance before the transformations. Fit PCA and LDA for all training images (12x16, 192-dimensional in vectorized form) by choosing 5-dimensional subspace for both PCA and LDA. Transform both train and test examples to this low-dimensional feature representation. Concatenate each sequence to single vector size of 5x1x(5+5). Similar to task 2.1, do the PCA and LDA fusion using NN and evaluate the performance on testset. Show confusion matrix and F1 scores of the results. </p>\n",
    "\n",
    "Note: Standardize the data along each axis.\n",
    "<br>\n",
    "\n",
    "Document your work, evaluate the results, and analyse the outcomes (The expected F1 score for this task should generally fall within the range of 40 to 50)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2\n",
    "\n",
    "### Your code begins here ###\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c349269722f7b4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 3. Feature extraction and feature-level fusion for multimodal classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-61ec26decd69ed9d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='task3'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Assigment.</b> <b>Task 3.</b>\n",
    "\n",
    "Prepare new feature sets for each modality and combine them to single feature representation. Compare two classifiers from scikit-learn. Train classifiers using joint feature presentation. Evaluate and compare the result using testing dataset. Do the subtasks given as \n",
    "<br>   \n",
    "\n",
    "<p> <b>3.1</b> Similar to task 2.1, calculate PCA for accelerometer, but choose now the 10 largest principal components as 10-dim feature vector for each window. In addition, for each window calculate mean and standard deviation of each three acc channels as statistical features, resulting 6-dimensional vector. Combine these to 36-dimensional final feature vector.</p>\n",
    "\n",
    "Document your work.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1\n",
    "\n",
    "### Your code begins here ###\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task3'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "<p> <b>3.2</b> Similar to task 2.2, calculate the PCA for depth images using same setup, but now choose the 10 largest principal components as feature vector. Concatenate the image sequence forming 50-dimensional feature vector from each windowed example.</p>\n",
    "\n",
    "Document your work.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2\n",
    "\n",
    "### Your code begins here ###\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task3'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "<p> <b>3.3</b> Form a joint feature presentation of features extracted in 3.1 and 3.2, resulting 86-dimensional feature vector for each example. Normalize data between 0-1 using the training dataset. Use support vector machine (SVM) with RBF-kernel and Gaussian naiveBayes classifier (use default parameter values for both classifiers). Train the classifiers and evaluate and compare classifiers on testset using confusion matrices and F1 scores.</p>\n",
    "\n",
    "Note: Normalize the data along each axis.\n",
    "<br>\n",
    "\n",
    "Document your work, evaluate the results, and analyse the outcomes. (The expected F1 score for this task should generally fall within the range of 55 to 70)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3\n",
    "\n",
    "### Your code begins here ###\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cedfc7478c461525",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 4. Decision-level fusion for multimodal classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-21056ef018219662",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='task4'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Assigment.</b> <b>Task 4.</b>\n",
    "\n",
    "Use features calculated for each modality in task 3. Choose base classifier for each modality from scikit-learn. Train classifiers for each modality feature presentations separately and combine the outputs in decision level. Evaluate and compare the result on testing dataset. Do the subtasks given as \n",
    "<br>\n",
    "<br> \n",
    "<p> <b>4.1</b> Use base classifiers of support vector machine (SVM) with RBF-kernel and AdaBoost classifier (with random_state=0). \n",
    "Normalize data between 0-1 using the training dataset. Train the base classifiers by tuning the model parameters (<i>C</i> parameter and RBF-kernel <i>gamma</i> in SVM as well as <i>n_estimators</i> and <i>learning_rate</i> in Adaboost) using 10-fold cross-validation on training dataset to find optimal set of parameters (hint: use GridSearchCV from scikit-learn). For grid search use the following values $C = [0.1, 1.0, 10.0, 100.0]$, $gamma=[0.1, 0.25, 0.5, 0.75, 1.0, 2.0]$, $n\\_estimators = [50, 100, 500, 1000]$, and $learning\\_rate = [0.1, 0.25, 0.5, 0.75,1.0]$.<br>\n",
    "Choose the best parameters and train the classifiers for each modality on whole training dataset. Is there a possibility that classifiers will overfit to training data using this parameter selection strategy? If so, why? </p>\n",
    "\n",
    "Note: Normalize the data along each axis.\n",
    "<br>\n",
    "\n",
    "Document your work, answer the given question, evaluate the results, and analyse the outcomes.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1\n",
    "\n",
    "### Your code begins here ###\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task4'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "\n",
    "<p> <b>4.2</b> Predict probabilistic outputs of each trained classifier for both modalities using the test set. </p>\n",
    "<br>\n",
    "Document your work, evaluate the results, and analyse the outcomes.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2\n",
    "\n",
    "### Your code begins here ###\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task4'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "<p> <b>4.3</b> Combine the probabilistic outputs of different modalities by fixed classification rules: max, min, prod, and sum. Evaluate, compare, and analyse the final combined results using confusion matrices and F1 scores. Show results for each base classifier combinations (i.e., $SVM_{acc}+SVM_{depth}$, $AdaBoost_{acc}+AdaBoost_{depth}$, $SVM_{acc}+AdaBoost_{depth}$, $AdaBoost_{acc}+SVM_{depth}$)</p>\n",
    "<br>\n",
    "Document your work, evaluate the results, and analyse the outcomes.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3\n",
    "\n",
    "### Your code begins here ###\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d4f13fd6c3cbb70d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 5. Bonus task: Multimodal biometric identification of persons (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e082ae9d74f6755a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='task5'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Assigment.</b> <b>Task 5.</b>\n",
    "\n",
    "Can you build a classifier that recognizes the person who is performing the exercise? Use same 10 person dataset and split it so that first 25% of each long exercise sequence is used for training and rest 75% of each sequence is used for testing the classifier. Use same 5 second windowing with 3 seconds overlap to prepare the examples. Note that, now the person identity is the class label instead of exercise type. Max. 10 points are given but you can earn points from partial solution, as well.\n",
    "<br> \n",
    "<br> \n",
    "<p> <b>5.1</b> Build a classifier to identify persons based on the features and one of the models given in task 4 (max. 5 points).</p>\n",
    "<br> \n",
    "Document your work. Evaluate and compare the results using confusion matrix and F1 score.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1\n",
    "\n",
    "### Your code begins here ###\n",
    "\n",
    "### Your code ends here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task5'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "<p> <b>5.2</b> Can you build your own solution (using new features, new classification model or different fusion approaches) to beat the approach in Task 5.1 ? (max. 5 points) </p>\n",
    "<br>  \n",
    "Document your work. Evaluate and compare the results using confusion matrix and F1 score.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2\n",
    "\n",
    "### Your code begins here ###\n",
    "\n",
    "### Your code ends here ###"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
